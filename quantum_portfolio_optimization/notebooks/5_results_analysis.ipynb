{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Quantum Portfolio Optimization: Results Analysis\n",
       "\n",
       "This notebook analyzes the results of our quantum portfolio optimization implementations and compares them with classical approaches."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "import sys\n",
       "import os\n",
       "import time\n",
       "from scipy import stats\n",
       "\n",
       "# Add parent directory to path\n",
       "sys.path.append(os.path.abspath('..'))\n",
       "\n",
       "from experiments.experiment_1_basic import run_basic_experiment\n",
       "from experiments.experiment_2_cardinality import run_cardinality_experiment\n",
       "from experiments.experiment_3_sector import run_sector_experiment\n",
       "from experiments.experiment_4_scaling import run_scaling_experiment\n",
       "from benchmarks.performance_metrics import BenchmarkMetrics\n",
       "from utilities.visualization import PortfolioVisualization"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Basic Portfolio Optimization Experiment\n",
       "\n",
       "Let's run a basic portfolio optimization experiment comparing classical and quantum approaches."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Run basic experiment with a small number of assets and repetitions for demonstration\n",
       "basic_results = run_basic_experiment(n_assets=5, n_repetitions=2)\n",
       "\n",
       "# Extract average results\n",
       "avg_classical = basic_results['avg_classical']\n",
       "avg_quantum = basic_results['avg_quantum']\n",
       "comparison = basic_results['solution_comparison']\n",
       "time_comparison = basic_results['time_comparison']\n",
       "\n",
       "# Print summary\n",
       "print(\"Basic Portfolio Optimization Experiment Summary:\")\n",
       "print(f\"Number of assets: {basic_results['test_case']['n_assets']}\")\n",
       "print(f\"Target return: {basic_results['target_return']:.4f}\")\n",
       "print(f\"Number of bits for encoding: {basic_results['n_bits']}\")\n",
       "print(f\"Number of repetitions: {basic_results['n_repetitions']}\")\n",
       "\n",
       "print(\"\\nClassical Results:\")\n",
       "print(f\"Portfolio return: {avg_classical['portfolio_return']:.4f}\")\n",
       "print(f\"Portfolio risk: {avg_classical['portfolio_risk']:.4f}\")\n",
       "print(f\"Sharpe ratio: {avg_classical['portfolio_return'] / avg_classical['portfolio_risk']:.4f}\")\n",
       "print(f\"Average run time: {avg_classical['run_time']:.6f}s\")\n",
       "\n",
       "print(\"\\nQuantum Results:\")\n",
       "print(f\"Portfolio return: {avg_quantum['portfolio_return']:.4f}\")\n",
       "print(f\"Portfolio risk: {avg_quantum['portfolio_risk']:.4f}\")\n",
       "print(f\"Sharpe ratio: {avg_quantum['portfolio_return'] / avg_quantum['portfolio_risk']:.4f}\")\n",
       "print(f\"Average run time: {avg_quantum['run_time']:.6f}s\")\n",
       "\n",
       "print(\"\\nComparison:\")\n",
       "print(f\"Return difference: {comparison['return_diff_pct']:.2f}%\")\n",
       "print(f\"Risk difference: {comparison['risk_diff_pct']:.2f}%\")\n",
       "print(f\"Sharpe ratio difference: {comparison['sharpe_diff_pct']:.2f}%\")\n",
       "print(f\"Weight correlation: {comparison['weight_correlation']:.4f}\")\n",
       "print(f\"Speed comparison: Classical is {time_comparison['speedup']:.2f}x {'faster' if time_comparison['speedup'] > 1 else 'slower'}\")\n",
       "\n",
       "# Plot portfolio weights comparison\n",
       "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
       "\n",
       "# Create asset labels\n",
       "asset_names = [f\"Asset {i+1}\" for i in range(len(avg_classical['weights']))]\n",
       "\n",
       "# Classical weights\n",
       "ax1.bar(asset_names, avg_classical['weights'])\n",
       "ax1.set_title('Classical Portfolio Weights')\n",
       "ax1.set_xlabel('Assets')\n",
       "ax1.set_ylabel('Weight')\n",
       "ax1.set_ylim(0, max(np.max(avg_classical['weights']), np.max(avg_quantum['weights'])) * 1.1)\n",
       "\n",
       "# Quantum weights\n",
       "ax2.bar(asset_names, avg_quantum['weights'])\n",
       "ax2.set_title('Quantum Portfolio Weights')\n",
       "ax2.set_xlabel('Assets')\n",
       "ax2.set_ylabel('Weight')\n",
       "ax2.set_ylim(0, max(np.max(avg_classical['weights']), np.max(avg_quantum['weights'])) * 1.1)\n",
       "\n",
       "plt.tight_layout()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Portfolio Optimization with Cardinality Constraints\n",
       "\n",
       "Now, let's analyze the results of portfolio optimization with cardinality constraints."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Run cardinality experiment with a small number of assets and repetitions for demonstration\n",
       "cardinality_results = run_cardinality_experiment(n_assets=8, max_assets=3, n_repetitions=2)\n",
       "\n",
       "# Extract average results\n",
       "avg_classical = cardinality_results['avg_classical']\n",
       "avg_quantum = cardinality_results['avg_quantum']\n",
       "comparison = cardinality_results['solution_comparison']\n",
       "time_comparison = cardinality_results['time_comparison']\n",
       "\n",
       "# Print summary\n",
       "print(\"Cardinality-Constrained Portfolio Optimization Experiment Summary:\")\n",
       "print(f\"Number of assets: {cardinality_results['test_case']['n_assets']}\")\n",
       "print(f\"Maximum number of assets: {cardinality_results['max_assets']}\")\n",
       "print(f\"Target return: {cardinality_results['target_return']:.4f}\")\n",
       "print(f\"Number of bits for encoding: {cardinality_results['n_bits']}\")\n",
       "print(f\"Number of repetitions: {cardinality_results['n_repetitions']}\")\n",
       "\n",
       "print(\"\\nClassical Results:\")\n",
       "print(f\"Portfolio return: {avg_classical['portfolio_return']:.4f}\")\n",
       "print(f\"Portfolio risk: {avg_classical['portfolio_risk']:.4f}\")\n",
       "print(f\"Sharpe ratio: {avg_classical['portfolio_return'] / avg_classical['portfolio_risk']:.4f}\")\n",
       "print(f\"Average run time: {avg_classical['run_time']:.6f}s\")\n",
       "\n",
       "print(\"\\nQuantum Results:\")\n",
       "print(f\"Portfolio return: {avg_quantum['portfolio_return']:.4f}\")\n",
       "print(f\"Portfolio risk: {avg_quantum['portfolio_risk']:.4f}\")\n",
       "print(f\"Sharpe ratio: {avg_quantum['portfolio_return'] / avg_quantum['portfolio_risk']:.4f}\")\n",
       "print(f\"Average run time: {avg_quantum['run_time']:.6f}s\")\n",
       "print(f\"Average number of assets: {avg_quantum['num_assets']:.1f}\")\n",
       "\n",
       "print(\"\\nComparison:\")\n",
       "print(f\"Return difference: {comparison['return_diff_pct']:.2f}%\")\n",
       "print(f\"Risk difference: {comparison['risk_diff_pct']:.2f}%\")\n",
       "print(f\"Sharpe ratio difference: {comparison['sharpe_diff_pct']:.2f}%\")\n",
       "print(f\"Weight correlation: {comparison['weight_correlation']:.4f}\")\n",
       "print(f\"Speed comparison: Classical is {time_comparison['speedup']:.2f}x {'faster' if time_comparison['speedup'] > 1 else 'slower'}\")\n",
       "\n",
       "# Plot portfolio weights comparison\n",
       "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
       "\n",
       "# Create asset labels\n",
       "asset_names = [f\"Asset {i+1}\" for i in range(len(avg_classical['weights']))]\n",
       "\n",
       "# Classical weights\n",
       "ax1.bar(asset_names, avg_classical['weights'])\n",
       "ax1.set_title(f'Classical Portfolio Weights (Max Assets: {cardinality_results[\"max_assets\"]})')\n",
       "ax1.set_xlabel('Assets')\n",
       "ax1.set_ylabel('Weight')\n",
       "ax1.set_ylim(0, max(np.max(avg_classical['weights']), np.max(avg_quantum['weights'])) * 1.1)\n",
       "ax1.tick_params(axis='x', rotation=45)\n",
       "\n",
       "# Quantum weights\n",
       "ax2.bar(asset_names, avg_quantum['weights'])\n",
       "ax2.set_title(f'Quantum Portfolio Weights (Avg Assets: {avg_quantum[\"num_assets\"]:.1f})')\n
       "ax2.set_xlabel('Assets')\n",
    "ax2.set_ylabel('Weight')\n",
    "ax2.set_ylim(0, max(np.max(avg_classical['weights']), np.max(avg_quantum['weights'])) * 1.1)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Portfolio Optimization with Sector Constraints\n",
    "\n",
    "Let's analyze the results of portfolio optimization with sector constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run sector experiment with a small number of repetitions for demonstration\n",
    "sector_results = run_sector_experiment(n_repetitions=1)\n",
    "\n",
    "# Extract average results\n",
    "avg_classical = sector_results['avg_classical']\n",
    "avg_quantum = sector_results['avg_quantum']\n",
    "comparison = sector_results['solution_comparison']\n",
    "time_comparison = sector_results['time_comparison']\n",
    "\n",
    "# Print summary\n",
    "print(\"Sector-Constrained Portfolio Optimization Experiment Summary:\")\n",
    "print(f\"Number of assets: {len(sector_results['test_case']['asset_names'])}\")\n",
    "print(f\"Sectors: {set(sector_results['test_case']['sectors'])}\")\n",
    "print(f\"Target return: {sector_results['target_return']:.4f}\")\n",
    "print(f\"Number of repetitions: {sector_results['n_repetitions']}\")\n",
    "\n",
    "print(\"\\nClassical Results:\")\n",
    "print(f\"Portfolio return: {avg_classical['portfolio_return']:.4f}\")\n",
    "print(f\"Portfolio risk: {avg_classical['portfolio_risk']:.4f}\")\n",
    "print(f\"Sharpe ratio: {avg_classical['portfolio_return'] / avg_classical['portfolio_risk']:.4f}\")\n",
    "print(\"Sector allocation:\")\n",
    "for sector_id, allocation in avg_classical['sector_allocation'].items():\n",
    "    sector_name = list(set(sector_results['test_case']['sectors']))[sector_id]\n",
    "    print(f\"  {sector_name}: {allocation:.4f}\")\n",
    "print(f\"Average run time: {avg_classical['run_time']:.6f}s\")\n",
    "\n",
    "print(\"\\nQuantum Results:\")\n",
    "print(f\"Portfolio return: {avg_quantum['portfolio_return']:.4f}\")\n",
    "print(f\"Portfolio risk: {avg_quantum['portfolio_risk']:.4f}\")\n",
    "print(f\"Sharpe ratio: {avg_quantum['portfolio_return'] / avg_quantum['portfolio_risk']:.4f}\")\n",
    "print(\"Sector allocation:\")\n",
    "for sector_id, allocation in avg_quantum['sector_allocation'].items():\n",
    "    sector_name = list(set(sector_results['test_case']['sectors']))[sector_id]\n",
    "    print(f\"  {sector_name}: {allocation:.4f}\")\n",
    "print(f\"Average run time: {avg_quantum['run_time']:.6f}s\")\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Return difference: {comparison['return_diff_pct']:.2f}%\")\n",
    "print(f\"Risk difference: {comparison['risk_diff_pct']:.2f}%\")\n",
    "print(f\"Sharpe ratio difference: {comparison['sharpe_diff_pct']:.2f}%\")\n",
    "print(f\"Weight correlation: {comparison['weight_correlation']:.4f}\")\n",
    "print(f\"Speed comparison: Classical is {time_comparison['speedup']:.2f}x {'faster' if time_comparison['speedup'] > 1 else 'slower'}\")\n",
    "\n",
    "# Show sector allocation figure\n",
    "sector_results['figures']['sector_allocation']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scaling Analysis\n",
    "\n",
    "Let's analyze how the performance of quantum and classical approaches scales with portfolio size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run scaling experiment with a small range and repetitions for demonstration\n",
    "scaling_results = run_scaling_experiment(asset_range=[5, 8, 10], n_repetitions=1)\n",
    "\n",
    "# Extract results\n",
    "asset_range = scaling_results['asset_range']\n",
    "classical_times = scaling_results['classical_times']\n",
    "quantum_times = scaling_results['quantum_times']\n",
    "hybrid_times = scaling_results['hybrid_times']\n",
    "classical_risks = scaling_results['classical_risks']\n",
    "quantum_risks = scaling_results['quantum_risks']\n",
    "hybrid_risks = scaling_results['hybrid_risks']\n",
    "scaling_analysis = scaling_results['scaling_analysis']\n",
    "\n",
    "# Print summary\n",
    "print(\"Scaling Analysis Summary:\")\n",
    "print(f\"Asset range: {asset_range}\")\n",
    "print(f\"Number of bits for encoding: {scaling_results['n_bits']}\")\n",
    "print(f\"Number of repetitions: {scaling_results['n_repetitions']}\")\n",
    "\n",
    "print(\"\\nScaling Exponents:\")\n",
    "print(f\"Classical: O(n^{scaling_analysis['classical_exponent']:.2f})\")\n",
    "print(f\"Quantum: O(n^{scaling_analysis['quantum_exponent']:.2f})\")\n",
    "\n",
    "# Show scaling plots\n",
    "scaling_results['figures']['linear_scaling']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comprehensive Performance Analysis\n",
    "\n",
    "Let's perform a comprehensive analysis of the performance metrics across all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Collect performance metrics from all experiments\n",
    "experiments = [\n",
    "    ('Basic', basic_results),\n",
    "    ('Cardinality', cardinality_results),\n",
    "    ('Sector', sector_results)\n",
    "]\n",
    "\n",
    "# Create dataframes for comparison\n",
    "metrics_data = []\n",
    "for name, result in experiments:\n",
    "    # Classical metrics\n",
    "    classical_metrics = {\n",
    "        'Experiment': name,\n",
    "        'Method': 'Classical',\n",
    "        'Return': result['avg_classical']['portfolio_return'],\n",
    "        'Risk': result['avg_classical']['portfolio_risk'],\n",
    "        'Sharpe': result['avg_classical']['portfolio_return'] / result['avg_classical']['portfolio_risk'],\n",
    "        'Time': result['avg_classical']['run_time']\n",
    "    }\n",
    "    metrics_data.append(classical_metrics)\n",
    "    \n",
    "    # Quantum metrics\n",
    "    quantum_metrics = {\n",
    "        'Experiment': name,\n",
    "        'Method': 'Quantum',\n",
    "        'Return': result['avg_quantum']['portfolio_return'],\n",
    "        'Risk': result['avg_quantum']['portfolio_risk'],\n",
    "        'Sharpe': result['avg_quantum']['portfolio_return'] / result['avg_quantum']['portfolio_risk'],\n",
    "        'Time': result['avg_quantum']['run_time']\n",
    "    }\n",
    "    metrics_data.append(quantum_metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"Performance Metrics Across Experiments:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Return comparison\n",
    "sns.barplot(x='Experiment', y='Return', hue='Method', data=metrics_df, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Portfolio Return Comparison')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Risk comparison\n",
    "sns.barplot(x='Experiment', y='Risk', hue='Method', data=metrics_df, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Portfolio Risk Comparison')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Sharpe ratio comparison\n",
    "sns.barplot(x='Experiment', y='Sharpe', hue='Method', data=metrics_df, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Sharpe Ratio Comparison')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Execution time comparison\n",
    "sns.barplot(x='Experiment', y='Time', hue='Method', data=metrics_df, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Execution Time Comparison')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quantum Advantage Analysis\n",
    "\n",
    "Let's analyze when quantum approaches might provide an advantage over classical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create analysis of potential quantum advantage\n",
    "advantage_data = {\n",
    "    'Portfolio Characteristic': [\n",
    "        'Small portfolio (< 10 assets)',\n",
    "        'Medium portfolio (10-50 assets)',\n",
    "        'Large portfolio (> 50 assets)',\n",
    "        'No constraints',\n",
    "        'Cardinality constraints',\n",
    "        'Sector constraints',\n",
    "        'Minimum/maximum investment constraints',\n",
    "        'Convex objective function',\n",
    "        'Non-convex objective function'\n",
    "    ],\n",
    "    'Classical Advantage': [\n",
    "        'High', # Small portfolio\n",
    "        'Medium', # Medium portfolio\n",
    "        'Low', # Large portfolio\n",
    "        'High', # No constraints\n",
    "        'Low', # Cardinality constraints\n",
    "        'Medium', # Sector constraints\n",
    "        'Medium', # Min/max constraints\n",
    "        'High', # Convex objective\n",
    "        'Low' # Non-convex objective\n",
    "    ],\n",
    "    'Quantum Advantage': [\n",
    "        'Low', # Small portfolio\n",
    "        'Medium', # Medium portfolio\n",
    "        'High', # Large portfolio\n",
    "        'Low', # No constraints\n",
    "        'High', # Cardinality constraints\n",
    "        'Medium', # Sector constraints\n",
    "        'Medium', # Min/max constraints\n",
    "        'Low', # Convex objective\n",
    "        'High' # Non-convex objective\n",
    "    ],\n",
    "    'Notes': [\n",
    "        'Classical algorithms are efficient for small portfolios',\n",
    "        'Quantum benefit starts to emerge with increased complexity',\n",
    "        'Quantum approaches may scale better for very large portfolios',\n",
    "        'Classical methods excel at unconstrained convex optimization',\n",
    "        'Quantum naturally handles discrete constraints (NP-hard problem)',\n",
    "        'Both approaches viable, quantum slightly better for complex sectors',\n",
    "        'Both approaches viable with similar performance',\n",
    "        'Classical convex optimizers are highly efficient',\n",
    "        'Quantum handles non-convex landscapes better (global optimization)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "advantage_df = pd.DataFrame(advantage_data)\n",
    "print(\"Quantum Advantage Analysis:\")\n",
    "print(advantage_df)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create numeric mapping for advantage levels\n",
    "advantage_map = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "classical_numeric = [advantage_map[level] for level in advantage_data['Classical Advantage']]\n",
    "quantum_numeric = [advantage_map[level] for level in advantage_data['Quantum Advantage']]\n",
    "\n",
    "# Create heatmap data\n",
    "heatmap_data = np.array([classical_numeric, quantum_numeric]).T\n",
    "heatmap_df = pd.DataFrame(\n",
    "    heatmap_data, \n",
    "    index=advantage_data['Portfolio Characteristic'],\n",
    "    columns=['Classical', 'Quantum']\n",
    ")\n",
    "\n",
    "# Plot heatmap\n",
    "ax = sns.heatmap(\n",
    "    heatmap_df, \n",
    "    annot=True, \n",
    "    cmap='coolwarm',\n",
    "    cbar_kws={'label': 'Advantage Level (1=Low, 3=High)'},\n",
    "    fmt='.0f'\n",
    ")\n",
    "plt.title('Quantum vs. Classical Advantage by Portfolio Characteristic')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Future Work and Potential Improvements\n",
    "\n",
    "Based on our analysis, here are some promising directions for future work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create future work dataframe\n",
    "future_work_data = {\n",
    "    'Area': [\n",
    "        'Algorithm Improvements',\n",
    "        'Algorithm Improvements',\n",
    "        'Algorithm Improvements',\n",
    "        'Problem Representation',\n",
    "        'Problem Representation',\n",
    "        'Hybrid Approaches',\n",
    "        'Hybrid Approaches',\n",
    "        'Hardware Integration',\n",
    "        'Hardware Integration',\n",
    "        'Application Extensions'\n",
    "    ],\n",
    "    'Future Work': [\n",
    "        'Develop adaptive VQE ansÃ¤tze specialized for portfolio optimization',\n",
    "        'Explore higher-order QAOA (p>1) with optimized mixer Hamiltonians',\n",
    "        'Implement error mitigation techniques for near-term quantum devices',\n",
    "        'Investigate efficient binary encoding schemes for portfolio weights',\n",
    "        'Develop direct amplitude encoding for continuous portfolio weights',\n",
    "        'Create adaptive hybrid solvers that dynamically switch between classical and quantum components',\n",
    "        'Implement quantum-assisted Monte Carlo methods for risk estimation',\n",
    "        'Test implementations on real quantum hardware (D-Wave, IBM, etc.)',\n",
    "        'Develop hardware-aware compilation strategies for portfolio circuits',\n",
    "        'Extend to multi-period portfolio optimization problems'\n",
    "    ],\n",
    "    'Priority': [\n",
    "        'High',\n",
    "        'Medium',\n",
    "        'High',\n",
    "        'Medium',\n",
    "        'Low',\n",
    "        'High',\n",
    "        'Medium',\n",
    "        'High',\n",
    "        'Medium',\n",
    "        'Low'\n",
    "    ],\n",
    "    'Potential Impact': [\n",
    "        'Significant performance improvement for gate-based quantum computers',\n",
    "        'Better solution quality for complex portfolios',\n",
    "        'Make quantum approaches viable on noisy devices',\n",
    "        'Reduce qubit requirements for large portfolios',\n",
    "        'Potentially more natural representation for continuous weights',\n",
    "        'Leverage strengths of both classical and quantum methods',\n",
    "        'Improve risk estimation with quantum sampling advantage',\n",
    "        'Validate theoretical advantages on real hardware',\n",
    "        'Reduce circuit depth for realistic implementation',\n",
    "        'Address more realistic portfolio management scenarios'\n",
    "    ]\n",
    "}\n",
    "\n",
    "future_work_df = pd.DataFrame(future_work_data)\n",
    "print(\"Future Work and Potential Improvements:\")\n",
    "print(future_work_df)\n",
    "\n",
    "# Create priority distribution plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "priority_counts = future_work_df['Priority'].value_counts().reindex(['High', 'Medium', 'Low'])\n",
    "ax = priority_counts.plot(kind='bar', color=['red', 'orange', 'green'])\n",
    "plt.title('Future Work Priority Distribution')\n",
    "plt.xlabel('Priority Level')\n",
    "plt.ylabel('Number of Tasks')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(priority_counts):\n",
    "    ax.text(i, v + 0.1, str(v), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create area distribution plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "area_counts = future_work_df['Area'].value_counts()\n",
    "area_counts.plot(kind='bar', color=plt.cm.viridis(np.linspace(0, 1, len(area_counts))))\n",
    "plt.title('Future Work by Research Area')\n",
    "plt.xlabel('Research Area')\n",
    "plt.ylabel('Number of Tasks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've analyzed the results of our quantum portfolio optimization implementations and compared them with classical approaches. Key findings include:\n",
    "\n",
    "1. **Basic Portfolio Optimization**: Classical methods are generally faster and more accurate for small, unconstrained portfolios, but quantum approaches show promise for larger problems.\n",
    "\n",
    "2. **Cardinality Constraints**: Quantum methods naturally handle discrete constraints, showing potential advantage for cardinality-constrained portfolios, which are NP-hard problems.\n",
    "\n",
    "3. **Sector Constraints**: Both approaches perform similarly for sector-constrained portfolios, with quantum methods showing slight advantages for complex constraints.\n",
    "\n",
    "4. **Scaling Analysis**: Quantum approaches potentially scale better than classical methods as the number of assets increases, although current quantum simulators are limited by classical hardware.\n",
    "\n",
    "5. **Quantum Advantage**: The most promising areas for quantum advantage are in large portfolios with discrete constraints and non-convex objective functions.\n",
    "\n",
    "Our analysis suggests that hybrid classical-quantum approaches currently offer the best trade-off between performance and practicality, leveraging the strengths of both paradigms. As quantum hardware improves and algorithms advance, we anticipate growing advantages for quantum portfolio optimization in complex financial scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}